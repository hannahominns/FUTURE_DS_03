# -*- coding: utf-8 -*-
"""Task 3.2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pMRV8QOkQvIEpigcrFHbLIzzthED_bPw
"""



import pandas as pd

# Load the Excel file into a pandas DataFrame
df = pd.read_excel("/content/Natural Hair in The Bahamas (Females) (Responses).xlsx")

# Display the first few rows of the DataFrame
display(df.head())

# Display information about the DataFrame
display(df.info())

import re

# Select the relevant text columns
text_columns = [
    'If your answer was yes to the previous question, what was the reason?',
    'Explain a situation in which you were bullied/judged for your hair?',
    'How did you feel when you were bullied/judged for your hair?',
    'What do you think was the reason behind you being bullied/judged?',
    'Do you believe the treatment of all natural hair in The Bahamas is equal and fair? Explain your answer.',
    'Do you think society in The Bahamas is changing its view of natural hair for the better or worst? Based on your answer, how is it visible in everyday life?'
]

df_text = df[text_columns].copy()

# Handle missing values by filling with an empty string
df_text = df_text.fillna('')

# Combine the text from the selected columns into a single column
df_text['combined_text'] = df_text.apply(lambda row: ' '.join(row.values.astype(str)), axis=1)

# Clean the combined text: remove special characters and convert to lowercase
df_text['cleaned_text'] = df_text['combined_text'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\s]', '', x.lower()))

# Display the first few rows of the DataFrame with the new columns
display(df_text.head())

# Analyze the distribution of sentiment categories
sentiment_distribution = df_text['sentiment'].value_counts()

# Display the distribution
display(sentiment_distribution)

import matplotlib.pyplot as plt
import seaborn as sns

# Visualize the sentiment distribution
plt.figure(figsize=(8, 6))
sns.barplot(x=sentiment_distribution.index, y=sentiment_distribution.values)
plt.title('Sentiment Distribution')
plt.xlabel('Sentiment Category')
plt.ylabel('Number of Responses')
plt.show()

from sklearn.feature_extraction.text import TfidfVectorizer

# Initialize TF-IDF Vectorizer
# Consider only words that appear in at least 2 documents and in no more than 85% of the documents
tfidf_vectorizer = TfidfVectorizer(max_df=0.85, min_df=2, stop_words='english')

# Fit and transform the cleaned text data
tfidf_matrix = tfidf_vectorizer.fit_transform(df_text['cleaned_text'])

# Get feature names (words)
feature_names = tfidf_vectorizer.get_feature_names_out()

# Sum TF-IDF scores for each word across all documents
sum_tfidf = tfidf_matrix.sum(axis=0)

# Create a dictionary of words and their summed TF-IDF scores
tfidf_scores = [(word, sum_tfidf[0, idx]) for word, idx in tfidf_vectorizer.vocabulary_.items()]

# Sort the words by their TF-IDF scores in descending order
tfidf_scores = sorted(tfidf_scores, key=lambda x: x[1], reverse=True)

# Display the top 20 keywords
print("Top 20 Keywords:")
for word, score in tfidf_scores[:20]:
    print(f"{word}: {score:.4f}")

# Get the top 20 keywords and their scores for visualization
top_keywords = tfidf_scores[:20]
words = [item[0] for item in top_keywords]
scores = [item[1] for item in top_keywords]

# Create a bar chart of the top keywords
plt.figure(figsize=(10, 8))
sns.barplot(x=scores, y=words, palette='viridis', hue=words, legend=False)
plt.title('Top 20 Keywords by TF-IDF Score')
plt.xlabel('TF-IDF Score')
plt.ylabel('Keywords')
plt.tight_layout()
plt.show()

# Generate a summary report
summary = f"""
## Analysis Summary

**Sentiment Analysis:**
The sentiment analysis using VADER shows that out of {len(df_text)} responses, {sentiment_distribution.get('Positive', 0)} were classified as Positive and {sentiment_distribution.get('Negative', 0)} as Negative. There were {sentiment_distribution.get('Neutral', 0)} Neutral responses.

**Keyword Analysis:**
The top 20 keywords identified through TF-IDF analysis are:
"""

for word, score in tfidf_scores[:20]:
    summary += f"- {word}: {score:.4f}\n"

summary += """

**Observations:**
Based on the sentiment distribution, the majority of the responses were classified as positive by the VADER model. However, it is important to note that as discussed earlier, VADER may not fully capture the nuances of responses describing negative experiences. The keyword analysis highlights terms such as 'people', 'standards', 'natural', 'european', and 'girls', suggesting that the feedback often revolves around societal perceptions and standards related to natural hair.
"""

print(summary)

# Generate a summary report
summary = f"""
## Analysis Summary

**Sentiment Analysis:**
The sentiment analysis using VADER shows that out of {len(df_text)} responses, {sentiment_distribution.get('Positive', 0)} were classified as Positive and {sentiment_distribution.get('Negative', 0)} as Negative. There were {sentiment_distribution.get('Neutral', 0)} Neutral responses.

**Keyword Analysis:**
The top 20 keywords identified through TF-IDF analysis are:
"""

for word, score in tfidf_scores[:20]:
    summary += f"- {word}: {score:.4f}\n"

summary += """

**Observations:**
Based on the sentiment distribution, the majority of the responses were classified as positive by the VADER model. However, it is important to note that as discussed earlier, VADER may not fully capture the nuances of responses describing negative experiences. The keyword analysis highlights terms such as 'people', 'standards', 'natural', 'european', and 'girls', suggesting that the feedback often revolves around societal perceptions and standards related to natural hair.
"""

print(summary)